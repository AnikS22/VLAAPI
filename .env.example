# VLA Inference API Platform - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
APP_NAME="VLA Inference API"
APP_VERSION="1.0.0"
ENVIRONMENT=development  # development, staging, production
DEBUG=true
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1  # Number of uvicorn workers (set to CPU cores in production)

# CORS Settings
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["*"]
CORS_ALLOW_HEADERS=["*"]

# =============================================================================
# DATABASE SETTINGS
# =============================================================================
# PostgreSQL Connection
DATABASE_URL=postgresql+asyncpg://vlaapi:password@localhost:5432/vlaapi
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_POOL_RECYCLE=3600

# Database Migration
ALEMBIC_CONFIG=alembic.ini

# =============================================================================
# REDIS SETTINGS
# =============================================================================
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5

# =============================================================================
# VLA MODEL SETTINGS
# =============================================================================
# Model Selection (comma-separated list)
ENABLED_MODELS=openvla-7b  # openvla-7b, pi0, pi0-fast

# HuggingFace Settings
HF_HOME=/models/huggingface
HF_TOKEN=  # Optional: for gated models
TRANSFORMERS_CACHE=/models/transformers

# Model Inference
DEFAULT_MODEL=openvla-7b
GPU_DEVICE=0  # CUDA device ID
VLA_MODEL_DTYPE=bfloat16  # float32, float16, bfloat16
LOW_CPU_MEM_USAGE=true
TRUST_REMOTE_CODE=true

# Inference Queue Settings
INFERENCE_QUEUE_MAX_SIZE=100
INFERENCE_BATCH_SIZE=4
INFERENCE_BATCH_TIMEOUT_MS=50
INFERENCE_MAX_WORKERS=2

# =============================================================================
# SAFETY SETTINGS
# =============================================================================
# Rule-Based Safety
SAFETY_ENABLE_WORKSPACE_CHECK=true
SAFETY_ENABLE_VELOCITY_CHECK=true
SAFETY_ENABLE_COLLISION_CHECK=true

# Safety Thresholds
SAFETY_DEFAULT_THRESHOLD=0.8  # Minimum safety score (0.0-1.0)
SAFETY_VELOCITY_LIMIT_LINEAR=0.5  # m/s
SAFETY_VELOCITY_LIMIT_ANGULAR=1.0  # rad/s
SAFETY_ACCELERATION_LIMIT=2.0  # m/s^2

# Workspace Bounds (default, can be overridden per request)
SAFETY_WORKSPACE_X_MIN=-0.5
SAFETY_WORKSPACE_X_MAX=0.5
SAFETY_WORKSPACE_Y_MIN=-0.5
SAFETY_WORKSPACE_Y_MAX=0.5
SAFETY_WORKSPACE_Z_MIN=0.0
SAFETY_WORKSPACE_Z_MAX=0.8

# ML Safety Classifier (pluggable)
SAFETY_CLASSIFIER_ENABLED=false
SAFETY_CLASSIFIER_PATH=/models/safety_classifier.onnx
SAFETY_CLASSIFIER_THRESHOLD=0.85

# =============================================================================
# AUTHENTICATION & SECURITY
# =============================================================================
# API Key Settings
API_KEY_PREFIX=vla_live  # or vla_test for test keys
API_KEY_LENGTH=32  # bytes (256 bits)
API_KEY_HASH_ALGORITHM=sha256

# JWT Settings (for admin dashboard and user authentication)
JWT_SECRET_KEY=  # Generate with: openssl rand -hex 32
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# Security
SECRET_KEY=  # Generate with: openssl rand -hex 32
ALLOWED_HOSTS=["localhost", "127.0.0.1"]

# =============================================================================
# STRIPE BILLING SETTINGS
# =============================================================================
# Stripe API Keys (get from https://dashboard.stripe.com/apikeys)
STRIPE_API_KEY=  # sk_test_... or sk_live_...
STRIPE_PUBLISHABLE_KEY=  # pk_test_... or pk_live_...
STRIPE_WEBHOOK_SECRET=  # whsec_... (for webhook signature verification)

# Stripe Price IDs (create in Stripe Dashboard > Products)
STRIPE_PRICE_ID_PRO=  # price_... for Pro tier ($499/mo)
STRIPE_PRICE_ID_ENTERPRISE=  # price_... for Enterprise tier (custom)

# Enable/Disable Stripe Integration
ENABLE_STRIPE=false  # Set to true in production with real keys

# =============================================================================
# RATE LIMITING
# =============================================================================
# Token Bucket Configuration
RATE_LIMIT_ENABLED=true
RATE_LIMIT_STORAGE_URL=redis://localhost:6379/0

# Default Tier Limits (override per customer in database)
RATE_LIMIT_FREE_RPM=10  # requests per minute
RATE_LIMIT_FREE_RPD=1000  # requests per day
RATE_LIMIT_FREE_MONTHLY=10000

RATE_LIMIT_PRO_RPM=100
RATE_LIMIT_PRO_RPD=10000
RATE_LIMIT_PRO_MONTHLY=100000

RATE_LIMIT_ENTERPRISE_RPM=1000
RATE_LIMIT_ENTERPRISE_RPD=100000
RATE_LIMIT_ENTERPRISE_MONTHLY=  # Empty = unlimited

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
# Prometheus Metrics
METRICS_ENABLED=true
METRICS_PORT=9090
PROMETHEUS_PUSHGATEWAY_URL=http://localhost:9091

# Logging
LOG_FORMAT=json  # json or text
LOG_FILE=/var/log/vlaapi/app.log
LOG_ROTATION_SIZE=100MB
LOG_ROTATION_COUNT=10

# Sentry (Optional)
SENTRY_DSN=
SENTRY_ENVIRONMENT=development
SENTRY_TRACES_SAMPLE_RATE=0.1

# GPU Monitoring
GPU_MONITORING_ENABLED=true
GPU_MONITORING_INTERVAL_SECONDS=5

# =============================================================================
# MONITORING & GPU
# =============================================================================
# Prometheus Metrics
ENABLE_PROMETHEUS=true
ENABLE_GPU_MONITORING=true
GPU_POLL_INTERVAL=5  # seconds

# =============================================================================
# DATA PIPELINE & EMBEDDINGS
# =============================================================================
# Embedding Settings
ENABLE_EMBEDDINGS=true
INSTRUCTION_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2  # 384-dim
IMAGE_EMBEDDING_MODEL=openai/clip-vit-base-patch32  # 512-dim CLIP
EMBEDDING_CACHE_TTL=300  # seconds
EMBEDDING_DIMENSION=384
EMBEDDING_BATCH_SIZE=32

# Vector Database
PGVECTOR_ENABLED=true
VECTOR_INDEX_TYPE=ivfflat  # ivfflat or hnsw
VECTOR_INDEX_LISTS=100
VECTOR_INDEX_PROBES=10

# Data Pipeline
DATA_PIPELINE_BATCH_SIZE=100
DATA_PIPELINE_WORKERS=4
DATA_PIPELINE_QUEUE_SIZE=1000

# =============================================================================
# STORAGE & BACKENDS
# =============================================================================
# S3/MinIO Configuration
ENABLE_S3_STORAGE=false
S3_ENDPOINT=  # Leave empty for AWS S3, or specify MinIO endpoint
S3_BUCKET=vla-training-data
S3_REGION=us-east-1
S3_ACCESS_KEY=
S3_SECRET_KEY=

# Storage Paths
STORAGE_RAW_DATA_PATH=/data/raw
STORAGE_PROCESSED_DATA_PATH=/data/processed
STORAGE_EMBEDDINGS_PATH=/data/embeddings
STORAGE_TEMP_PATH=/data/temp

# =============================================================================
# DATA COLLECTION & RETENTION
# =============================================================================
# Collection Settings
DATA_COLLECTION_ENABLED=true
COLLECTION_BATCH_TIMEOUT_MS=5000
COLLECTION_MAX_BATCH_SIZE=500

# Data Retention (days, -1 = forever)
RAW_DATA_RETENTION_DAYS=90
AGGREGATED_DATA_RETENTION_DAYS=365
SAFETY_DATA_RETENTION_DAYS=-1  # Keep safety incidents forever

# ETL & Data Pipeline
ETL_ENABLED=true
ETL_SCHEDULE_HOUR=2  # UTC hour for daily ETL run (0-23)
ETL_BATCH_SIZE=1000

# Consent & Privacy
DEFAULT_CONSENT_TIER=none  # none, basic, full
CONSENT_CACHE_TTL=600  # seconds

# Anonymization
ANONYMIZATION_LEVEL=full  # none, partial, full
ANONYMIZATION_HASH_SALT=change-in-production

# =============================================================================
# IMAGE PROCESSING
# =============================================================================
# OCR Settings
OCR_ENABLED=true
OCR_LANGUAGES=["en", "es", "fr"]  # EasyOCR language codes
OCR_GPU_ENABLED=true
OCR_CONFIDENCE_THRESHOLD=0.5

# Image Processing
IMAGE_MAX_SIZE_MB=50
IMAGE_ALLOWED_FORMATS=["jpg", "png", "bmp", "webp"]
IMAGE_QUALITY_PRESET=balanced  # fast, balanced, high

# =============================================================================
# ROBOT CONFIGURATIONS
# =============================================================================
# Default Robot Type
DEFAULT_ROBOT_TYPE=franka_panda
ROBOT_CONFIGS_DIR=/config/robot_configs

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
# Request Timeout
REQUEST_TIMEOUT_SECONDS=30
INFERENCE_TIMEOUT_SECONDS=10

# Connection Limits
MAX_CONCURRENT_REQUESTS=100
KEEP_ALIVE_TIMEOUT=5

# GPU Memory Management
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Auto-reload on code changes
AUTO_RELOAD=true

# Mock Models (for testing without GPU)
USE_MOCK_MODELS=false

# Database Seeding
SEED_DATABASE=false
SEED_ADMIN_EMAIL=admin@example.com
SEED_ADMIN_API_KEY=

# =============================================================================
# DEPLOYMENT
# =============================================================================
# Docker
DOCKER_REGISTRY=
DOCKER_IMAGE_TAG=latest

# Health Checks
HEALTH_CHECK_INTERVAL_SECONDS=30
HEALTH_CHECK_TIMEOUT_SECONDS=5
